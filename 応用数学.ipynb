{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "応用数学.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIrOs9J/tyQWFwRllbQ91C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lake198/Study-AI/blob/main/%E5%BF%9C%E7%94%A8%E6%95%B0%E5%AD%A6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m6tF0MmThjH"
      },
      "source": [
        "# 線形代数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXycaD-5Dh0"
      },
      "source": [
        "##固有値・固有ベクトル\n",
        "\n",
        " 正方行列$A$に対して\\\n",
        " \\\n",
        " $$\n",
        " A\\vec{x}=\\lambda\\vec{x}\\cdots(1)\n",
        " $$\\\n",
        " となる0でないベクトル$\\vec{x}$が存在する時、$λ$を固有値、$\\vec{x}$を固有ベクトルと呼ぶ。(1)を変形すると\\\n",
        "\\\n",
        "$$\n",
        " (A-\\lambda I)\\vec{x}=\\vec{0}\\cdots(2)\n",
        "$$\\\n",
        "となるが、(2)式が$\\vec{x}=\\vec{0}$以外の解を持つ条件は、\\\n",
        "\\\n",
        "$$\n",
        "det(A-\\lambda I)=0\\cdots(3)\n",
        "$$\\\n",
        "である。\n",
        "(3)式を変数$λ$の方程式として解くことで固有値$λ$が得られる。次に固有値$λ$を(2)式に代入し、連立方程式を解くことで固有ベクトル$\\vec{x}$が得られる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPFIT7Qz5b72"
      },
      "source": [
        "##固有値分解\n",
        "\n",
        "正方行列$A$が固有値$λ$と固有ベクトル$\\bf{x}$を持つ時、\\\n",
        "\\\n",
        "$$\n",
        "A=X \\Lambda X^{-1}\\cdots(4)\n",
        "$$\\\n",
        "と変形することを固有値分解という。この時\\\n",
        "\\\n",
        "$$\n",
        "\\Lambda = \\left(\n",
        "\\begin{array}{ccc}\n",
        "\\lambda_{1} & & \\\\\n",
        " & \\lambda_{2} & \\\\\n",
        " & & \\ddots\n",
        "\\end{array}\n",
        "\\right), \\quad X=(\\bf{x_1}, \\bf{x_2}, \\cdots)\n",
        "$$\\\n",
        "である。固有値分解を行うことで、$A^n$の計算を用意に行う事ができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsF-DPbiKmm9"
      },
      "source": [
        "##特異値分解\n",
        "行列$A$が正方行列でない場合でも、$AA^\\mathrm{T}$および$A^\\mathrm{T}A$を固有値分解することで、$A=USV^{-1}$の形に分解することができる。これを特異値分解と呼ぶ。この時、$U$は左特異ベクトル、$V$は右特異ベクトル、$S$は特異値である。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVe_Z-mkTz88"
      },
      "source": [
        "# 確率・統計"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meuEF0HbXSA_"
      },
      "source": [
        "#同時確率・周辺確率\n",
        "確率変数$X$, $Y$に対して$X=x$, $Y=y$ が同時に起こる確率を同時確率と呼び、$p(X=x,Y=y)$で表す。\n",
        "\n",
        "また注目事象を$X=x$とした時、注目していない方の事象$Y$が取りうる全ての変数$y$に対する同時確率を足し合わせたものを$X=x$の周辺確率と呼び、$p(X=x)$で表す。すなわち、\\\n",
        "\\\n",
        "$$\n",
        "p(X=x)=\\sum_{y} p(X=x,Y=y)\n",
        "$$\\\n",
        "である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1gErNy_T5A1"
      },
      "source": [
        "## 条件付き確率とベイズ則\n",
        "確率変数$X$, $Y$に対して、ある特定の条件$Y=y$の元で$X=x$となる確率を条件付き確率と呼び、$p(X=x \\mid Y=y)$で表す。条件付き確率は周辺確率と同時確率を用いて、以下の式で表される。\\\n",
        "\\\n",
        "$$\n",
        "p(X=x \\mid Y=y)=\\frac{p(X=x,Y=y)}{p(Y=y)}\\cdots(1)\n",
        "$$\\\n",
        "また条件$Y=y$の元で確率変数$X$が取りうる全ての値$x$について、条件付き確率を求めて足し合わせた結果は1となる。すなわち\\\n",
        "\\\n",
        "$$\n",
        "\\sum_{x} p(X=x \\mid Y=y)=1\\cdots(2)\n",
        "$$\\\n",
        "一方、ある事業$X=x$が起こった時、その原因が$Y=y$である確率は、条件付き確率$p(Y=y \\mid X=x)$で表される。この時、条件付き確率と同時確率、周辺確率との関係から、\\\n",
        "\\\n",
        "$$\n",
        "p(Y=y \\mid X=x)=\\frac{p(X=x,Y=y)}{p(X=x)}\\cdots(3)\n",
        "$$\n",
        "\\\n",
        "ここで(1)式と(3)式の関係から\\\n",
        "\\\n",
        "$$\n",
        "p(Y=y \\mid X=x)=\\frac{p(X=x \\mid Y=y)\\cdot p(Y=y)}{p(X=x)}\\cdots(4)\n",
        "$$\n",
        "\\\n",
        "(4)式をベイズの定理と呼ぶ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1xQj-CV4Jn4"
      },
      "source": [
        "## 統計量（平均・分散・標準偏差・期待値）\n",
        "あるデータ分布$x_i(x_1,x_2,\\cdots)$に対して、その重心に相当する値を平均値と呼び$\\bar{x}$で表す。データのばらつきを計る指標として、平均値$\\bar{x}$から各データ値$x_i$までの距離の2乗の総和を分散と呼び、$σ^2$で表す。$σ$は標準偏差と呼び、分散の平方根をとる事で各データと単位を揃えたものである。期待値はデータ$x_i$と確率$p(x_i)$の積を取りうる全ての値について足し合わせた値であり、1回の試行で得られる結果の平均値となる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14lwgEu57h6i"
      },
      "source": [
        "## 確率分布\n",
        "■二項分布：成功を「1」、失敗を「0」とする試行を$N$回行ったとき、成功する回数$X$が従う確率分布を二項分布と呼ぶ。\\\n",
        "\\\n",
        "$$\n",
        "P(X=k)={}_n C_kp^k(1-p)^{n-k}\n",
        "$$\n",
        "\\\n",
        "■ポアソン分布：二項分布において$n$が非常に大きく$p$が非常に小さい場合に$X$が従う確率分布をポアソン分布と呼ぶ。ポアソン分布は$np=λ$とおいた時、試行$n$回中に平均$λ$回起こる事象が$k$回起こる確率である。\\\n",
        "\\\n",
        "$$\n",
        "P(X=k)=\\frac{e^{-k}λ^k}{k!}\n",
        "$$\n",
        "\\\n",
        "■正規分布：正規分布は自然界の多くの事象について、確率変数$X$が従うと仮定できる連続型確率分布である。母集団の平均値$が\\mu$、分散が$σ^2$で表される時、確率変数$X$の確率密度関数$f(x)$は次式で表される。\\\n",
        "\\\n",
        "$$\n",
        "f(x)=\\frac{1}{\\sqrt{2\\pi}σ}exp \\left(\n",
        "\\frac{-(x-\\mu)^2}{2σ^2}\n",
        "\\right)\n",
        "$$\n",
        "\\\n",
        "ここで$Z=(X-\\mu)/σ$と変数変換すると、確率変数$Z$は平均値が0、分散が1の標準正規分布に従う。また$Z$の確率密度関数$f(z)$は下式となる。\\\n",
        "\\\n",
        "$$\n",
        "f(x)=\\frac{1}{\\sqrt{2\\pi}}exp \\left(\n",
        "\\frac{-z^2}{2}\n",
        "\\right)\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNx0gNwOn4R7"
      },
      "source": [
        "## 情報理論\n",
        "■自己情報量\\\n",
        "確率変数$X$について、$X=x$となる事が判った時の情報量を自己情報量と呼び、\\\n",
        "\\\n",
        "$$\n",
        "i(x)=-logP(x)\n",
        "$$\n",
        "\\\n",
        "として定義される。この定義から、確率の低い結果が起こる事が判った時ほど情報量は高くなる。また複数の結果が同時に起こる場合、確率は各々の結果が起こる確率の積となるが、情報量は対数の性質から各情報量の足し合わせとなる。\\\n",
        "\\\n",
        "■平均情報量\n",
        "確率変数$X$について、取りうる全ての変数$x$に対する情報量の期待値を平均情報量と呼び、次式で定義される。\\\n",
        "\\\n",
        "$$\n",
        "H(X)=-\\sum_xP(x)logP(x)\n",
        "$$\n",
        "\\\n",
        "情報量はその事象が起こるかどうかの不確実性とも捉える事ができるため、平均情報量は情報エントロピーとも呼ばれる。すなわち確率変数$X$の取りうる値が一つしかない場合、$X=x$となる事は確実（$P(x)=1$）であり、情報量$H(X)=0$ となる"
      ]
    }
  ]
}